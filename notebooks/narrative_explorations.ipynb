{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random \n",
    "import yaml\n",
    "import re\n",
    "import dill\n",
    "\n",
    "from shapnarrative_metrics.llm_tools import llm_wrappers\n",
    "from shapnarrative_metrics.misc_tools.manipulations import full_inversion, shap_permutation\n",
    "from shapnarrative_metrics.llm_tools.generation import GenerationModel\n",
    "from shapnarrative_metrics.llm_tools.extraction import ExtractionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary keys and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/keys.yaml\") as f:\n",
    "    dict=yaml.safe_load(f)\n",
    "api_key = dict[\"API_keys\"][\"OpenAI\"]\n",
    "replicate_key = dict[\"API_keys\"][\"Replicate\"]\n",
    "anthropic_key=dict[\"API_keys\"][\"Anthropic\"]\n",
    "mistral_key=dict[\"API_keys\"][\"Mistral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=\"fifa\"\n",
    "\n",
    "with open(f'data/{dataset_name}_dataset/dataset_info', 'rb') as f:\n",
    "   ds_info= pickle.load(f)\n",
    "\n",
    "with open(f'data/{dataset_name}_dataset/RF.pkl', 'rb') as f:\n",
    "   trained_model=pickle.load(f)\n",
    "\n",
    "train=pd.read_parquet(f\"data/{dataset_name}_dataset/train_cleaned.parquet\")\n",
    "test=pd.read_parquet(f\"data/{dataset_name}_dataset/test_cleaned.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=14\n",
    "\n",
    "idx=882\n",
    "\n",
    "idx=4\n",
    "x=test[test.columns[0:-1]].loc[[idx]]\n",
    "y=test[test.columns[-1]].loc[[idx]]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPERATURE=0\n",
    "MANIP=True\n",
    "\n",
    "gpt = llm_wrappers.GptApi(api_key, model=\"gpt-4o\", system_role=\"You are a teacher that explains AI predictions.\", temperature=TEMPERATURE)\n",
    "llama_generation = llm_wrappers.LlamaAPI(api_key=replicate_key , model=\"llama-3-70b-instruct\",system_role=\"You are a teacher that explains AI predictions.\", temperature=TEMPERATURE)\n",
    "claude_generation = llm_wrappers.ClaudeApi(api_key=anthropic_key , model=\"claude-3-5-sonnet-20240620\",system_role=\"You are a teacher that explains AI predictions.\", temperature=TEMPERATURE)\n",
    "mistral_generation=llm_wrappers.MistralApi(api_key=mistral_key, model=\"mistral-large-2407\" ,system_role=\"You are a teacher that explains AI predictions.\", temperature=TEMPERATURE)\n",
    "generator=GenerationModel(ds_info=ds_info, llm=gpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.gen_variables(trained_model,x,y,tree=True)\n",
    "generator.explanation_list[0].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=generator.generate_story_prompt(iloc_pos=0,manipulate=MANIP, manipulation_func=full_inversion)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narratives =generator.generate_stories(trained_model, x , y , tree=True, manipulate=MANIP)\n",
    "narrative_split=re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', narratives[0])\n",
    "for sentence in narrative_split:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor=ExtractionModel(ds_info=ds_info, llm=gpt)\n",
    "extraction=extractor.generate_extractions(narratives)\n",
    "extraction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.explanation_list[0].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_diff, sign_diff , value_diff, real_rank, extracted_rank=extractor.get_diff(extraction[0],generator.explanation_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_diff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
